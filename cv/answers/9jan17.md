# 1. Planar Homography

A planar homography is a **linear transformation** on homogeneous coordinates that maps points on one plane to points on another plane¹². It can be represented by a **non-singular 3x3 matrix** H such that x' = Hx, where x and x' are the homogeneous coordinates of the corresponding points³⁵. A planar homography is also called a **collineation** or a **projective transformation** because it preserves the **incidence** and **cross-ratio** of points and lines⁴⁵.

# 2. Stereo matching

The correct answer is **c. Correlation is computed using a block of pre-defined size**. This is because using a single pixel information (b) is not reliable and can lead to many false matches¹³, while using the histogram of the entire image (a) is not sensitive to local variations and can also produce incorrect matches². Using a block of pre-defined size (c) allows to capture more contextual information and reduce the ambiguity of matching²³. However, the optimal size of the block depends on the scene and the resolution of the images³.

# 3. SIFT

The correct answer is **b. A set of images processed with the same Gaussian filtering but at different spatial resolutions**.

An octave in the SIFT algorithm is a set of images that are generated by progressively blurring the original image. The blurring is done using a Gaussian filter, which is a filter that smooths out an image by averaging the values of neighboring pixels. The original image is the first image in the octave, and each subsequent image is blurred by a factor of two. This means that the second image in the octave is half the resolution of the first image, the third image is half the resolution of the second image, and so on.

The SIFT algorithm uses octaves to find features that are invariant to scale changes. This means that a feature that is detected in one image of an octave will also be detected in the other images of the octave, even if the feature is scaled up or down.

Option a is incorrect because the images in an octave are not processed with different Gaussian filtering. All of the images in an octave are processed with the same Gaussian filter.

Option c is incorrect because an octave is not the co-presence of multiple feature points at different spatial resolutions. An octave is a set of images, and each image can contain multiple feature points. However, the feature points in different images of the same octave are not necessarily the same feature points.

I hope this explanation is helpful. Let me know if you have any other questions.

# 4. Camera Matrix

The correct answer is **a. Represents only the intrinsic parameters of the camera**.

The camera matrix is a 3x3 matrix that describes the relationship between the coordinates of a point in the world and its projection onto the image plane. The intrinsic parameters of the camera are the focal length, principal point, and skew. These parameters are fixed for a given camera, and do not change when the camera is moved.

The extrinsic parameters of the camera are the location and orientation of the camera in the world. These parameters can change when the camera is moved, and are not represented in the camera matrix.

Option b is incorrect because the camera matrix does not represent the extrinsic parameters of the camera.

Option c is incorrect because the camera matrix does change in case the camera is moved. The intrinsic parameters of the camera do not change, but the extrinsic parameters can change, and this will affect the camera matrix.

# 5. LK optical flow

The correct answer is **b. g^(L-1) = 2g^L + d^L**.

In the pyramidal implementation of the LK optical flow, the image is first downsampled to create a lower resolution image. The LK optical flow is then computed on the lower resolution image. The result of the LK optical flow is then upsampled to the original resolution.

The information from the lower resolution image is propagated to the original resolution image by doubling the estimated optical flow and adding it to the previous estimate. This is done to ensure that the estimated optical flow is smooth across the different resolution levels.

Option a is incorrect because it doubles the estimated optical flow and the displacement vector. This will make the estimated optical flow too large and will not be smooth across the different resolution levels.

Option c is incorrect because it doubles the estimated optical flow and the displacement vector twice. This will make the estimated optical flow even larger and will not be smooth across the different resolution levels.