# 2. SIFT

SIFT extraction is a process of finding and describing distinctive features in an image that are invariant to scale, rotation, and other transformations. It consists of four main steps³:

- **Scale-space extrema detection**: The image is convolved with Gaussian filters at different scales and the difference of Gaussians (DoG) is computed between adjacent scales. The local maxima and minima of the DoG are potential keypoints.
- **Keypoint localization**: The potential keypoints are refined by eliminating low-contrast or poorly localized ones. A Taylor series expansion is used to determine the location and scale of each keypoint with sub-pixel accuracy.
- **Orientation assignment**: One or more orientations are assigned to each keypoint based on the local image gradient directions. This ensures that the keypoint descriptor is invariant to rotation.
- **Keypoint descriptor**: A 128-dimensional vector is computed for each keypoint based on the image gradients in a 16x16 neighborhood around the keypoint. The vector is normalized to enhance contrast invariance.

The result of SIFT extraction is a set of keypoints and descriptors that can be used for various applications, such as image matching, object recognition, or image stitching¹²⁴.

# 3. Kalman vs particle filter

Kalman filter and particle filter are two methods for estimating the state of a dynamic system from noisy observations. They have different assumptions, advantages, and disadvantages¹²³⁴.

- **Kalman filter** assumes that the system and the observation models are linear and that the noise is Gaussian. It uses a recursive algorithm that updates the state estimate and its covariance matrix based on the prediction and the measurement. It is optimal for linear Gaussian systems, but it may fail for nonlinear or non-Gaussian systems. It has low computational complexity, but it requires the knowledge of the system and observation matrices and the noise statistics.
- **Particle filter** does not assume any specific form of the system or the observation models or the noise distribution. It uses a set of particles (samples) that represent the state estimate and its probability distribution. It updates the particles using a sequential Monte Carlo method that involves prediction, weighting, and resampling steps. It can handle nonlinear and non-Gaussian systems, but it may suffer from particle degeneration or impoverishment. It has high computational complexity, but it does not require the knowledge of the system or observation matrices or the noise statistics.

In summary, Kalman filter is more efficient and accurate for linear Gaussian systems, while particle filter is more flexible and robust for nonlinear non-Gaussian systems.

# 4. Motion detection and optical flow

The correct answer to this question is **B**, which states:

"Moving pixels belonging to a uniform region are not detected"

This is because the optical flow equation assumes that the intensity of a pixel does not change over time, which implies that the spatio-temporal intensity gradient is equal to the product of the spatial intensity gradient and the motion vector. However, if the pixel belongs to a uniform region, then the spatial intensity gradient is zero, which makes the optical flow equation indeterminate and the motion vector undefined. Therefore, motion detection is not possible for pixels in a uniform region.

Points A and C are incorrect because they are not consistent with the optical flow equation. Point A states:

"Objects with a pure translational motion model cannot be detected"

This is not true because the optical flow equation can handle pure translational motion as long as the spatial intensity gradient is nonzero and not parallel to the spatio-temporal intensity gradient. Point C states:

"Only in the case motion occurs along the surface tangent, motion can be detected"

This is not true because the optical flow equation can handle motion in any direction as long as the spatio-temporal intensity gradient is not parallel to the spatial intensity gradient. Motion along the surface tangent is a special case where the aperture problem occurs and the motion vector is ambiguous.

# 5. Viola Jones classifier

The correct answer is **b**. The Viola-Jones classifier uses a single-class approach to do face recognition¹²³⁴⁵. It is a boosted feature learning algorithm that combines a series of weak classifiers based on Haar-like features to form a strong classifier¹²³⁴⁵. The weak classifiers are selected and weighted using a modified AdaBoost algorithm¹²³⁴⁵. The strong classifier is then applied to a sliding window over the image to detect faces¹²³⁴⁵. Therefore, a is incorrect and c is also incorrect.

# 6. Good Features to Track

The correct answer is **c**. The "Good Features To Track" algorithm might show different performances depending on the level of blurring. This is because the algorithm evaluates the feature value in a pixel location by checking the **eigenvalues** of the **second-moment matrix**³⁴, which measures the **change in intensity** around that pixel⁶⁷. If the image is blurred, the intensity changes will be less pronounced and the algorithm will have a harder time finding good features to track.

