# ML and Neurocognitive Science

## Barrett et al.

In ML recently we assisted to the creaction of Deep Neural Network (DNNs), with millions of parameters, without handcrafted features and high performance, and in some way this can be similar to human brain: 
- first because in both cases there are an high number of interconnected elements (neurons), 
- both transform input in output (stimuli to complex response thanks to multiple processing stages)
- they both analyze high dimensional data.

### Analogies

- Receptive fields:
    - neurons in the visual cortex are specialized to process stimuli in specific spacial areas, with small receptive fields in the beginning and increasing in size in higher level areas of visual processing
        - receptive fields sensitivity increases in higher level areas, where also invariance to small transformations (can detect identity of object but not appearance) can be found
    - Using activation maximization, a field analysis method, we are able to synthesize images that maximally activate a neuron, and we can see the produced images are increasingly complex in higher level areas
- Ablation:
    - it consists in removing a part of the network and see how the performance changes, but it is difficult to do in humans, so we can use brain lesions to have an insight
    - in DNNs it is possible to silencing neurons and see their impact on the output, using structural pruning (removing neuron and outgoing weights)
        - network trained for generalization are more robust than those trained on memorizing labels (importance of neuron is measured by the sum of its effect, not class selectivity)
        - pruning and fine tuning active areas of research
- Dimensionality reduction
    - the brain codes information in a distributed way, necessitating multivariate analysis
        - multiple neurons encode the same information (2 neurons may fire almost identically)
        - information is encoded in a distributed manner (4 classes among 2 neurons)
        - correlation among units indicates that the activity can be reduced to a lower dimensional space
    - in DNNs an object-by-feature matrix from fully connected layer can be compressed by more than 80% almost all variance (few low dimensions explain differences between images)
- Representational geometries:
    - given 2 layers or 2 networks you can compare them using Canonical Correlation Analysis or PLScorrelation
        - they identify lower-level features that capture and maximize correlation/covariance between datasets
    - using Representational Similarity Analysis object-by-object similarity matrix can be constructed
    - neurobiological activation vectors can be predicted from DNN embeddings using linear regression

## Spicer and Sanborn

### Spatial methods

They consist of placing items in a multidimensional space and making use of their location to make conclusion about categorization. This can be done using location relative an hyperplane (perceptron/svm) or by computing its similarity to different prototypes or exemplars (means/centroid):
- in the case of prototypes, the similarity is computed using the mean of a category
- in the case of exemplars, the similarity is computed as a ratio between the similarity of the item to the category and the similarity of the item to the other categories (fit per class)
- using clustering algorithms, the items are grouped into clusters using distance within and between clusters, that can be either hard (one-to-one) or soft (fuzzy)

An example is the Generalized Context Model (GCM):

![Alt text](<images/Screenshot from 2023-06-19 10-35-42.png>)

### Logical methods and ANNs

- logical methods define items using logical statements concering the features of the target, identifying common elements within a dataset that can be defined using a set of rules: you search for rules (either probabilistic) that maximizes discrimination across stimuli
    - its adventage is that it is easy to interpret, and multiple rules can be combined to form complex rules, but creates hard boundaries
- with ANNs you don't make assumption, but directly implement the model, and while they become more complex, they better model human behaviour

## Conclusion

Asking what is the most accurate model is not the right question, because it depends on the task and you should focus on ones offering useful explorations of the ways in which human learning operates. Also, you have to consider if want to be able to understand the underlying representations, so you don't use just accuracy, but what confusions occur.

# Categories and Categorical Perception

# Categorical Perception

Categorical perception is the phenomenon where people perceive stimuli from different categories as more distinct from each other than stimuli within the same category. This concept introduces invariance in response to a functionally defined category, which is useful for rapid prediction, efficient memory, and data compression.

## Logic of Categorical Perception

### Demonstration Steps
1. **Select a Set of Stimuli**: Choose stimuli that cover a physical domain uniformly (e.g., sound frequencies from 100Hz to 8000Hz).
2. **Objective Distance Measure**: Use a measure like frequency space for sounds or colors.
3. **Operationalize Human Similarity**: Use similarity judgments, generalization, or confusion tests.
4. **Procedure**: 
   - Assign all stimuli to categories.
   - Obtain similarity judgments for within-category vs. between-category pairs, or evaluate categorization boundaries.

## Auditory Categorical Perception

### Example: Voice Onset Time (VOT)
- People discriminate speech sounds more sharply between different phonetic categories than within the same category.
- E.g., /b/ and /p/ sounds are easier to discriminate when they straddle a category boundary.

### Infant Studies
- Eimas et al. (1971) found that 4-month-old babies could differentiate stimuli with a 20ms VOT difference that crossed phonetic boundaries, showing early categorical perception.

## Related Phenomena in Audition

1. **Change Deafness**: Many participants fail to notice a change in speaker voice in a word repetition task (Vitevitch, 2003).
2. **Sine-wave Speech**: Expectations and learning impact whether a stimulus is perceived as speech.
3. **McGurk Effect**: Demonstrates the influence of multimodal inputs on auditory perception.

## Categorical Perception in Color

### Color Discrimination
- Discrimination is better across category boundaries than within the same category.
- For instance, distinguishing between green and blue is easier than distinguishing between two shades of green.
- This phenomenon can be measured using Commision Internationale de Lâ€™Eclairage (CIE) values to equate discriminability.

### Cross-Linguistic Differences
- Roberson, Davies, and Davidoff (2000) studied the Berinmo tribe, who use the term "nol" for both green and blue.
- Berinmo showed better discrimination for cross-category items between "nol" and "wor" (both green) than within-category items, unlike English speakers.

## Conclusion

Categorical perception highlights how the brain organizes sensory information into distinct categories, facilitating efficient processing and response. This concept is evident in both auditory and visual domains, demonstrating the impact of linguistic and cultural differences on perception.