# AI4People

## Ethical principles

### Beneficence: Promoting Well-Being, Preserving Dignity, and Sustaining the Planet

The well-being of all sentient creatures shall be promoted in any AI system, developed for the common good, helping many people as possible. Also preserving the dignity and the sustainability shall be considered, to continue prospering and giving the best to the future generations.

### Non‐maleficence: Privacy, Security and “Capability Caution”

Infragements on personal privacy and misuse of AI technologies shall be prevented. It is not clear if the AI or the humans developing it, be encouraged to not harm. 

### Autonomy: The Power to Decide (Whether to Decide)

Individuals have a right to make decisions for themselves about the treatment they do or not receive: typically, in medical context, this right is impaired when the patients lack the mental capacity to make decisions for themselves. In the case of AI, we willinly cede some of our decision-making power to machines, and we have to strike a balance between the decision-making power we keep for ourselves and the one we cede to machines. AI shall never hurt, deceive or destroy humans, as opposed to what humans may do to each other. Also, while the autonomy of humans shall be promoted, the autonomy of AI shall be restricted and eventually and made reversible when humans decide to do so: this is called "meta-autonomy", also known as "decide-to-delegate", where humans shall have the power to decide which decisions to take, exercising their freedom of choice.

### Justice: Promoting Prosperity and Preserving Solidarity

The development of AI shall promote justice and seek to eliminate all types of discrimination, contributing to global justice and equal access to the benefits, permitting the humans to flourish along with the AI. A risk using AI is that it may discriminate against some groups of people because of biases in the data used to train it. AI shall be used to correct past wrongs, to create shared benefits and to prevent the creation of new harms, also by respecting the interests of all parties impacted by the AI system.

### Explicability: Enabling the Other Principles Through Intelligibility and Accountability

AI shall be transparent, understandable and interpretable

## Opportunities and Risks for Society

The AI surely will have an impact on our life, the questions are by whom, how, where, and when this positive or negative impact will be felt: positive or negative because we have to use it in the correct way, not underusing it or overusing/misusing it.

### Who We Can Become: Enabling Human Self‐Realisation, Without Devaluing Human Abilities

AI may enable self-realisation, the ability to flourish in different areas. The risk here is the pace at which the obsolete skills will be replaced by the new ones, maybe causing some inequality and costs for the society.

### What We Can Do: Enhancing Human Agency, Without Removing Human Responsibility

When using AI, we can do more, better, and faster, thanks to its capabilities. Here, we have to remember that our responsibility is essential, causing a risk when it is missing, maybe because of "black box" mentality, seeing the output of the AI beyond our understanding. If developed correctly, AI can improve and multiply our possibilities and strengthen our moral agency.

### What We Can Achieve: Increasing Societal Capabilities, Without Reducing Human Control

When combining our intelligence with the AI one, we can find new solution to already existing problems and not (deseases, logistics, etc.). The risk that comes from this is the fact that may not need to be "in or on the loop" anymore, delegating our decisions to the AI, even if we are supposed to have an oversight on it, causing a reduction of our capabilities to monitor the performance of the AI, accumulating the risks. We have to find a balance between the opportunities offered by AI and our control over it.

### How We Can Interact: Cultivating Societal Cohesion, Without Eroding Human Self‐Determination

AI can help us dealing with coordination complexity, supporting more societal cohesion and collaboration with a possible risk of eroding our self-determination, caused by unplanned changes in human behaviour to accommodate the routines that make automation work and people’s lives easier. 

## Dual Advantage of an Ethical Approach

Compliance with the law is merely necessary but insufficient (playing according to the rules vs. playing well and winning). If we use an ethical approach, we can achieve a dual advantage: on one hand, you take advantage of the AI with the new opportunities it offers, and on the other hand, you anticipate, avoid or at least minimize costly risks (mitigation of risks). AI will be accepted by society if there are benefits and if the risks are minimized.

## Recommendations and Action points for a Good AI Society 

AI shall be designed and developed in ways that decrease inequality and increase shared benefits, equitably.

### Assessments

- Capacity of civil courts to address AI-related mistakes/harm and need for liability framework.
- Tasks/functions not suitable for AI delegation and consideration of societal values/public opinion.
- Sufficiency of existing regulations in providing a legislative framework for AI developments and need for ethics-based principles.

### Development

This is a list of recommendations aimed at enhancing the explicability and trustworthiness of AI systems that make socially significant decisions. The recommendations include:

- Developing a framework for AI explainability to provide individuals with a clear explanation of the decision-making process
    Improving the legal system's IT infrastructure to permit the scrutiny of algorithmic decisions in court
- Developing auditing mechanisms for AI systems to identify and address unwanted consequences
- Developing a redress process for harm inflicted by AI
- Developing agreed-upon metrics for the trustworthiness of AI products and services
- Developing a new EU oversight agency to protect public welfare through the evaluation and supervision of AI
- Developing a European observatory for AI to monitor developments and provide a forum for debate and consensus
- Developing legal instruments and contractual templates for a smooth human-machine collaboration in the workplace.

### Incentivisation

- Incentivize the development and use of socially preferable and environmentally friendly AI technologies within the EU.
- Incentivize a sustained, increased and coherent European research effort in AI that focuses on social good.
- Incentivize cross-disciplinary and cross-sectoral cooperation and debate on the intersection of technology, social issues, legal studies, and ethics.
- Incentivize the inclusion of ethical, legal, and social considerations in AI research projects, and regular review of legislation.
- Incentivize the development and use of lawfully de-regulated special zones for empirical testing and development of AI systems.
- Incentivize research on public perception and understanding of AI and its applications, and structured public consultation mechanisms for policy design.

### Support

To promote ethical AI use, support is suggested for:

- Self-regulatory codes of conduct for AI professionals with a focus on ethics and certification.

- Capacity building for corporate boards to handle AI ethical implications through training and ethics committees.

- Educational programs and public awareness on the societal, legal, and ethical impact of AI, including education in schools, employee training, and ethics education in academic curricula, as well as engagement with initiatives such as ITU AI for Good and UN SDGs.