# AI4People

## Ethical principles

### Beneficence: Promoting Well-Being, Preserving Dignity, and Sustaining the Planet

The well-being of all sentient creatures shall be promoted in any AI system, developed for the common good, helping many people as possible. Also preserving the dignity and the sustainability shall be considered, to continue prospering and giving the best to the future generations.

### Non‐maleficence: Privacy, Security and “Capability Caution”

Infragements on personal privacy and misuse of AI technologies shall be prevented. It is not clear if the AI or the humans developing it, be encouraged to not harm. 

### Autonomy: The Power to Decide (Whether to Decide)

Individuals have a right to make decisions for themselves about the treatment they do or not receive: typically, in medical context, this right is impaired when the patients lack the mental capacity to make decisions for themselves. In the case of AI, we willinly cede some of our decision-making power to machines, and we have to strike a balance between the decision-making power we keep for ourselves and the one we cede to machines. AI shall never hurt, deceive or destroy humans, as opposed to what humans may do to each other. Also, while the autonomy of humans shall be promoted, the autonomy of AI shall be restricted and eventually and made reversible when humans decide to do so: this is called "meta-autonomy", also known as "decide-to-delegate", where humans shall have the power to decide which decisions to take, exercising their freedom of choice.

### Justice: Promoting Prosperity and Preserving Solidarity

The development of AI shall promote justice and seek to eliminate all types of discrimination, contributing to global justice and equal access to the benefits, permitting the humans to flourish along with the AI. A risk using AI is that it may discriminate against some groups of people because of biases in the data used to train it. AI shall be used to correct past wrongs, to create shared benefits and to prevent the creation of new harms, also by respecting the interests of all parties impacted by the AI system.

### Explicability: Enabling the Other Principles Through Intelligibility and Accountability

AI shall be transparent, understandable and interpretable

## Opportunities and Risks for Society

## Dual Advantage of an Ethical Approach

Compliance with the law is merely necessary but insufficient (playing according to the rules vs. playing well and winning). If we use an ethical approach, we can achieve a dual advantage: on one hand, you take advantage of the AI with the new opportunities it offers, and on the other hand, you anticipate, avoid or at least minimize costly risks (mitigation of risks). AI will be accepted by society if there are benefits and if the risks are minimized.

## Recommendations and Action points for a Good AI Society 

AI shall be designed and developed in ways that decrease inequality and increase shared benefits, equitably.

### Assessments

- Capacity of civil courts to address AI-related mistakes/harm and need for liability framework.
- Tasks/functions not suitable for AI delegation and consideration of societal values/public opinion.
- Sufficiency of existing regulations in providing a legislative framework for AI developments and need for ethics-based principles.

### Development

This is a list of recommendations aimed at enhancing the explicability and trustworthiness of AI systems that make socially significant decisions. The recommendations include:

- Developing a framework for AI explainability to provide individuals with a clear explanation of the decision-making process
    Improving the legal system's IT infrastructure to permit the scrutiny of algorithmic decisions in court
- Developing auditing mechanisms for AI systems to identify and address unwanted consequences
- Developing a redress process for harm inflicted by AI
- Developing agreed-upon metrics for the trustworthiness of AI products and services
- Developing a new EU oversight agency to protect public welfare through the evaluation and supervision of AI
- Developing a European observatory for AI to monitor developments and provide a forum for debate and consensus
- Developing legal instruments and contractual templates for a smooth human-machine collaboration in the workplace.

### Incentivisation

- Incentivize the development and use of socially preferable and environmentally friendly AI technologies within the EU.
- Incentivize a sustained, increased and coherent European research effort in AI that focuses on social good.
- Incentivize cross-disciplinary and cross-sectoral cooperation and debate on the intersection of technology, social issues, legal studies, and ethics.
- Incentivize the inclusion of ethical, legal, and social considerations in AI research projects, and regular review of legislation.
- Incentivize the development and use of lawfully de-regulated special zones for empirical testing and development of AI systems.
- Incentivize research on public perception and understanding of AI and its applications, and structured public consultation mechanisms for policy design.

### Support

To promote ethical AI use, support is suggested for:

- Self-regulatory codes of conduct for AI professionals with a focus on ethics and certification.

- Capacity building for corporate boards to handle AI ethical implications through training and ethics committees.

- Educational programs and public awareness on the societal, legal, and ethical impact of AI, including education in schools, employee training, and ethics education in academic curricula, as well as engagement with initiatives such as ITU AI for Good and UN SDGs.