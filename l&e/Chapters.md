# AI Act 

## Definitions

An AI is a software that is capable of producing outputs such as content, predictions, recommendations, or decisions influencing the environment they interact with; they are developed using ML approaches (e.g. supervised, unsupervised, reinforcement, deep learning), logic and knowledge-based approaches (inductive programming, KB, inference and deduction engines and expert systems), or statistical approaches (e.g. Bayesian estimation, optimization methods).  

## Risk-based approach

The AI Act is a risk-based approach to AI regulation. There are four different risk levels, each with a different set of requirements. The risk levels are defined by the following criteria:

- Unacceptable risk (prohibited): like social scoring, facial recognition, dark-pattern AI or manipulation

    - The application that violates fundamental rights by subliminal techniques, manipulation, social scoring or real-time remote biometric identification systems in public spaces

- **High risk (conformity assessment): AI with application in education, employment, justice, immigration or law**

    - AI systems to be used as safety component of a product or a product itself with application in:

        - Critical infrastructure (e.g. transport)
        - Biometric ID systems
        - Educational and vocational training (e.g. automated scoring of exams)
        - Employment, workers management and access to self-employment (automated hiring or CV triage software)
        - Essential private and public services (e.g. automated welfare benefits systems)
        - Law enforcement systems that may with peopleâ€™s fundamental rights ('pre-crime' detection)
        -  Migration, asylum and border management (e.g.verification of authenticity of travel documents)
        - Administration of justice and democratic processes (e.g. automated sentencing assistance)

- Limited risk (transparency): like chatbots, deep fakes or emotion recognition systems

    - Providers have obbligation of transparency letting users know they are interacting with a machine rather than a human

- Minimal risk (code of conduct): like spam filters or video games

## Prohibited systems

